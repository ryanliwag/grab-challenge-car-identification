{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Libraries\n",
    "from __future__ import print_function, division\n",
    "import argparse\n",
    "import os\n",
    "import time\n",
    "import utils\n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "from torchvision import transforms\n",
    "from scipy.io import loadmat\n",
    "from PIL import Image\n",
    "import random\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import lr_scheduler\n",
    "import copy\n",
    "\n",
    "from matplotlib.pyplot import imshow\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "seed = 25\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "#using GPU\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = \"data/cars_train/\"\n",
    "car_annotations_path = \"data/devkit/cars_train_annos.mat\"\n",
    "car_metadata_path = \"data/devkit/cars_meta.mat\"\n",
    "\n",
    "#Load Meta Data\n",
    "meta_data = loadmat(car_metadata_path)\n",
    "meta_data = np.concatenate(meta_data[\"class_names\"][0])\n",
    "\n",
    "#nb_classes\n",
    "nb_classes = len(meta_data)\n",
    "\n",
    "#Load and split train, val and test samples\n",
    "dataset = utils.Load_Images(root_dir=root_dir, annotations_path=car_annotations_path, seed=seed, test_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class car_dataset(Dataset):\n",
    "    \"\"\"\n",
    "    Description:\n",
    "        Pytorch Dataset class for reading Car Dataset meta files and images.\n",
    "    Arguments:\n",
    "        files (list, required): \n",
    "        root_dir (str, required): Root directory path\n",
    "        meta_data (list, required): exctracted meta data\n",
    "    Returns a Dictionary\n",
    "    \"\"\"\n",
    "    def __init__(self, files, root_dir, meta_data, image_transform=None):\n",
    "        \n",
    "        self.root_dir = root_dir\n",
    "        self.image_transform = image_transform\n",
    "        \n",
    "        #image file names\n",
    "        self.image_files = [file[-1][0] for file in files]\n",
    "        \n",
    "        #Class ID\n",
    "        self.id = [file[-2][0] - 1 for file in files]\n",
    "        \n",
    "        #Class Name\n",
    "        self.class_name = [meta_data[file[-2][0] - 1][0] for file in files]\n",
    "        \n",
    "        #Get Car Year\n",
    "        self.carYear, self.carYear_ID = utils.get_Year(self.class_name)\n",
    "\n",
    "        #Get Car Maker\n",
    "        self.carMaker, self.carMaker_ID = utils.get_Maker(self.class_name)\n",
    "        \n",
    "        #Get Car Type\n",
    "        self.carType, self.carType_ID = utils.get_Type(self.class_name)\n",
    "        \n",
    "        #change and Move there is still time\n",
    "        self.year_count = len(np.unique(self.carYear_ID))\n",
    "        self.maker_count = len(np.unique(self.carMaker_ID))\n",
    "        self.type_count = len(np.unique(self.carType_ID))\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.id)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.root_dir, self.image_files[idx])\n",
    "        img = Image.open(img_path)\n",
    "        \n",
    "        if self.image_transform:\n",
    "            img = self.image_transform(img)\n",
    "        \n",
    "        target = torch.from_numpy(np.array(self.id[idx]))[0]\n",
    "        \n",
    "        class_count = {\n",
    "                      \"year\": self.year_count,\n",
    "                      \"maker\": self.maker_count,\n",
    "                      \"type\": self.type_count\n",
    "                     }\n",
    "\n",
    "        sample = {'Image':img, 'class_ID':target, \"class_name\":self.class_name[idx],\n",
    "                 'year_ID':self.carYear_ID[idx], 'maker_ID':self.carMaker_ID[idx],\n",
    "                 'type_ID':self.carType_ID[idx], \"class_count\":class_count}\n",
    "        \n",
    "        return sample\n",
    "    \n",
    "class ImbalancedDatasetSampler(torch.utils.data.sampler.Sampler):\n",
    "    \"\"\"Samples elements randomly from a given list of indices for imbalanced dataset creating\n",
    "        a weight depeding of the frequency of the class\n",
    "    Arguments:\n",
    "        dataset (list, optional): a list of indices\n",
    "        class_type (int, optional): \n",
    "    \"\"\"\n",
    "    def __init__(self, dataset, class_type):\n",
    "                      \n",
    "        self.indices = list(range(len(dataset)))\n",
    "        \n",
    "        self.num_samples = len(self.indices) \n",
    "        # distribution of classes in the dataset \n",
    "        label_to_count = {}\n",
    "        for idx in self.indices:\n",
    "            label = self._get_label(dataset, idx, class_type)\n",
    "            if label in label_to_count:\n",
    "                label_to_count[label] += 1\n",
    "            else:\n",
    "                label_to_count[label] = 1\n",
    "        # weight for each sample\n",
    "        weights = [1.0 / label_to_count[self._get_label(dataset, idx, class_type)] for idx in self.indices]\n",
    "        self.weights = torch.DoubleTensor(weights)\n",
    "\n",
    "    def _get_label(self, dataset, idx, class_type):\n",
    "        return dataset[idx][class_type].item()\n",
    "                \n",
    "    def __iter__(self):\n",
    "        return (self.indices[i] for i in torch.multinomial(\n",
    "                self.weights, self.num_samples, replacement=True))\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_transformers = {'training': transforms.Compose([transforms.Resize((224, 224)),\n",
    "                                                       transforms.RandomRotation(degrees=50),\n",
    "                                                       transforms.RandomHorizontalFlip(0.8),\n",
    "                                                       transforms.RandomPerspective(p=0.1),\n",
    "                                                     transforms.ColorJitter(brightness=0.8, contrast=0.8),\n",
    "                                                     transforms.ToTensor()]),\n",
    "                      'validation': transforms.Compose([transforms.Resize((224, 224)),\n",
    "                                                       transforms.ToTensor()])\n",
    "                     }\n",
    "    \n",
    "\n",
    "training_data = car_dataset(dataset[\"training\"],\n",
    "                            root_dir = root_dir,\n",
    "                            meta_data = meta_data,\n",
    "                            image_transform = image_transformers[\"training\"]\n",
    "                           )\n",
    "\n",
    "#\n",
    "train_loader = torch.utils.data.DataLoader(training_data, batch_size=15, \n",
    "                                           sampler=ImbalancedDatasetSampler(training_data, \"class_ID\"))\n",
    "\n",
    "#train_loader = torch.utils.data.DataLoader(training_data, batch_size=15, shuffle=True)\n",
    "\n",
    "validation_data = car_dataset(dataset[\"validation\"], \n",
    "                             root_dir = root_dir,\n",
    "                             meta_data = meta_data,\n",
    "                             image_transform  = image_transformers[\"validation\"])\n",
    "\n",
    "validation_loader = torch.utils.data.DataLoader(validation_data, \n",
    "                                                batch_size=15, shuffle=True)\n",
    "\n",
    "dataloaders = {\"training\":train_loader, \"validation\":validation_loader}\n",
    "dataSizes = {\"training\":len(dataset[\"training\"]), \"validation\":len(dataset[\"validation\"])}\n",
    "\n",
    "#Get Count per each Class\n",
    "class_year = training_data[0][\"class_count\"][\"year\"]\n",
    "class_maker = training_data[0][\"class_count\"][\"maker\"]\n",
    "class_type = training_data[0][\"class_count\"][\"type\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Pretrained Model\n",
    "#use Resnet 18 cause its small :)\n",
    "fr_model = torchvision.models.resnet18(pretrained=True)\n",
    "\n",
    "#freeze layers\n",
    "for param in fr_model.parameters():\n",
    "    param.requires_grad = False\n",
    "    \n",
    "print(fr_model)\n",
    "num_ftrs = fr_model.fc.in_features\n",
    "fr_model.fc = torch.nn.Linear(num_ftrs, 1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class multi_task_model(torch.nn.Module):\n",
    "    def __init__(self, base_model,nb_maker_classes, nb_type_classes):\n",
    "        super(multi_task_model, self).__init__()\n",
    "        \n",
    "        self.base_model = base_model\n",
    "        \n",
    "        self.x1 = torch.nn.Linear(1024, 512)\n",
    "        torch.nn.init.xavier_normal_(self.x1.weight) \n",
    "        self.bn1 = torch.nn.BatchNorm1d(512, eps = 2e-1)\n",
    "        \n",
    "        \n",
    "        self.x2 = torch.nn.Linear(512,512)\n",
    "        torch.nn.init.xavier_normal_(self.x2.weight)\n",
    "        self.bn2 = torch.nn.BatchNorm1d(512, eps = 2e-1)\n",
    "        \n",
    "        #adding one more on top of the heads\n",
    "        self.x3 = torch.nn.Linear(512, 256)\n",
    "        torch.nn.init.xavier_normal_(self.x3.weight)\n",
    "        \n",
    "        self.x4 = torch.nn.Linear(256, 256)\n",
    "        torch.nn.init.xavier_normal_(self.x4.weight)\n",
    "        \n",
    "        #Auxiliary tasks\n",
    "        self.y_maker = torch.nn.Linear(256, nb_maker_classes)\n",
    "        torch.nn.init.xavier_normal_(self.y_maker.weight)\n",
    "        self.y_type = torch.nn.Linear(256, nb_type_classes)\n",
    "        torch.nn.init.xavier_normal_(self.y_type.weight)\n",
    "        \n",
    "        #Main Task\n",
    "        self.y = torch.nn.Linear(256, 196)\n",
    "        torch.nn.init.xavier_normal_(self.y.weight)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x1 = self.base_model(x)\n",
    "        \n",
    "        x1 = self.bn1(F.relu(self.x1(x1)))\n",
    "        \n",
    "        #My auxiliary Tasks\n",
    "        y_maker_output = F.softmax(self.y_maker(self.x3(x1)))\n",
    "        y_type_output = F.softmax(self.y_type(self.x3(x1)))\n",
    "        \n",
    "        '''\n",
    "                #My auxiliary Tasks\n",
    "        y_maker_output = F.softmax(self.y_maker(self.x3(x1)))\n",
    "        y_type_output = F.softmax(self.y_type(self.x3(x1)))\n",
    "        '''\n",
    "        \n",
    "        x1 = self.bn2(F.relu(self.x2(x1)))\n",
    "        \n",
    "        y_class_output = F.softmax(self.y_maker(self.x3(x1)))\n",
    "        \n",
    "        return y_maker_output, y_type_output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
