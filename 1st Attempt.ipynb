{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "import random\n",
    "from scipy.io import loadmat\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "from PIL import Image\n",
    "from skimage import io\n",
    "\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.utils.data\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_size(filepath):\n",
    "    '''\n",
    "    Return Shape of Image\n",
    "    '''\n",
    "    im = Image.open(filepath)\n",
    "    im = np.asarray(im)\n",
    "    \n",
    "    return im.shape\n",
    "\n",
    "root_dir = \"data/cars_train/\"\n",
    "car_annotations_path = \"data/devkit/cars_train_annos.mat\"\n",
    "car_metadata_path = \"data/devkit/cars_meta.mat\"\n",
    "\n",
    "#Load Annotations\n",
    "annotations = loadmat(car_annotations_path)\n",
    "\n",
    "#Load Meta Data\n",
    "meta_data = loadmat(car_metadata_path)\n",
    "meta_data = np.concatenate(meta_data[\"class_names\"][0])\n",
    "\n",
    "#Filter by images with 3 dimensions (Having RGB layers)\n",
    "files = [filename for filename in annotations[\"annotations\"][0] if len(check_size(os.path.join(root_dir, filename[-1][0]))) == 3 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImbalancedDatasetSampler(torch.utils.data.sampler.Sampler):\n",
    "    \"\"\"Samples elements randomly from a given list of indices for imbalanced dataset\n",
    "    Arguments:\n",
    "        indices (list, optional): a list of indices\n",
    "        num_samples (int, optional): number of samples to draw\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dataset, indices=None, num_samples=None):\n",
    "                \n",
    "        # if indices is not provided, \n",
    "        # all elements in the dataset will be considered\n",
    "        self.indices = list(range(len(dataset))) \\\n",
    "            if indices is None else indices\n",
    "            \n",
    "        # if num_samples is not provided, \n",
    "        # draw `len(indices)` samples in each iteration\n",
    "        self.num_samples = len(self.indices) \\\n",
    "            if num_samples is None else num_samples\n",
    "            \n",
    "        # distribution of classes in the dataset \n",
    "        label_to_count = {}\n",
    "        for idx in self.indices:\n",
    "            label = self._get_label(dataset, idx)\n",
    "            if label in label_to_count:\n",
    "                label_to_count[label] += 1\n",
    "            else:\n",
    "                label_to_count[label] = 1\n",
    "                \n",
    "        # weight for each sample\n",
    "        weights = [1.0 / label_to_count[self._get_label(dataset, idx)]\n",
    "                   for idx in self.indices]\n",
    "        self.weights = torch.DoubleTensor(weights)\n",
    "\n",
    "    def _get_label(self, dataset, idx):\n",
    "        dataset_type = type(dataset)\n",
    "        if dataset_type is torchvision.datasets.MNIST:\n",
    "            return dataset.train_labels[idx].item()\n",
    "        elif dataset_type is torchvision.datasets.ImageFolder:\n",
    "            return dataset.imgs[idx][1]\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "                \n",
    "    def __iter__(self):\n",
    "        return (self.indices[i] for i in torch.multinomial(\n",
    "            self.weights, self.num_samples, replacement=True))\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToTensor(object):\n",
    "    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image, class_id = sample['Image'], sample['class_ID']\n",
    "        image = np.asarray(image)\n",
    "        image = image.transpose((2, 0, 1))\n",
    "        \n",
    "        tensor = torch.from_numpy(np.array(image/255).astype(np.float32))\n",
    "        \n",
    "        \n",
    "        return {'Image': tensor,\n",
    "                'class_ID': target,\n",
    "                'class_name': sample[\"class_name\"]}\n",
    "\n",
    "class car_dataset(Dataset):\n",
    "    \n",
    "    def __init__(self, files, root_dir, meta_data, transform=None, image_transform=None):\n",
    "        \n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.image_transform = image_transform\n",
    "        \n",
    "        #image file names\n",
    "        self.image_files = [file[-1][0] for file in files]\n",
    "        \n",
    "        #Class ID\n",
    "        self.id = [file[-2][0] for file in files]\n",
    "        \n",
    "        #Class Name\n",
    "        self.class_name = [meta_data[file[-2][0] - 1][0] for file in files]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.id)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.root_dir, self.image_files[idx])\n",
    "        img = Image.open(img_path)\n",
    "        \n",
    "        if self.image_transform:\n",
    "            img = self.image_transform(img)\n",
    "        \n",
    "        target = torch.from_numpy(np.array(self.id[idx]))\n",
    "        \n",
    "        sample = {'Image':img, 'class_ID':target, \"class_name\":self.class_name[idx]}\n",
    "        \n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = transforms.Compose([ToTensor()])\n",
    "image_transformer = transforms.Compose([transforms.RandomHorizontalFlip(0.5),\n",
    "                                        transforms.ColorJitter(brightness=0.4, contrast=0.4),\n",
    "                                        transforms.Resize((244,244)),\n",
    "                                        transforms.ToTensor(),\n",
    "                                        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "\n",
    "\n",
    "car_data = car_dataset(files = files,\n",
    "                       root_dir = root_dir,\n",
    "                       meta_data = meta_data,\n",
    "                       transform = transformer,\n",
    "                       image_transform = image_transformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.sampler import RandomSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_loader = torch.utils.data.DataLoader(car_data, batch_size=5, sampler=RandomSampler(car_data, replacement=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace)\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace)\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): ReLU(inplace)\n",
      "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): ReLU(inplace)\n",
      "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace)\n",
      "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): ReLU(inplace)\n",
      "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): ReLU(inplace)\n",
      "    (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (17): ReLU(inplace)\n",
      "    (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (19): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (20): ReLU(inplace)\n",
      "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (22): ReLU(inplace)\n",
      "    (23): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (24): ReLU(inplace)\n",
      "    (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (26): ReLU(inplace)\n",
      "    (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (29): ReLU(inplace)\n",
      "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (31): ReLU(inplace)\n",
      "    (32): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (33): ReLU(inplace)\n",
      "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (35): ReLU(inplace)\n",
      "    (36): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "    (1): ReLU(inplace)\n",
      "    (2): Dropout(p=0.5)\n",
      "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (4): ReLU(inplace)\n",
      "    (5): Dropout(p=0.5)\n",
      "    (6): Linear(in_features=4096, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "## Load the model based on VGG19\n",
    "vgg_based = torchvision.models.vgg19(pretrained=True)\n",
    "\n",
    "\n",
    "## freeze the layers\n",
    "for param in vgg_based.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Modify the last layer\n",
    "number_features = vgg_based.classifier[6].in_features\n",
    "features = list(vgg_based.classifier.children())[:-1] # Remove last layer\n",
    "features.extend([torch.nn.Linear(number_features, 1)])\n",
    "vgg_based.classifier = torch.nn.Sequential(*features)\n",
    "\n",
    "vgg_based = vgg_based.to(device)\n",
    "\n",
    "print(vgg_based)\n",
    "\n",
    "criterion = torch.nn.binary_cross_entropy()\n",
    "optimizer_ft =  torch.optim.SGD(vgg_based.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ">>> loss = nn.PoissonNLLLoss()\n",
    ">>> log_input = torch.randn(5, 2, requires_grad=True)\n",
    ">>> target = torch.randn(5, 2)\n",
    ">>> output = loss(log_input, target)\n",
    ">>> output.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'GeForce GTX 960'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        train_loss = 0\n",
    "\n",
    "        # Iterate over data.\n",
    "        for i, data in enumerate(dataset_loader):\n",
    "            inputs = data[\"Image\"]\n",
    "            labels = data[\"class_ID\"]\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            labels = labels.long()\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            with torch.set_grad_enabled(True):\n",
    "                outputs  = model(inputs)\n",
    "                print(outputs)\n",
    "                print(labels)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "            print('{} Loss: {:.4f}'.format('train', train_loss / dataset_sizes['train']))\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/4\n",
      "----------\n",
      "tensor([[-0.3554],\n",
      "        [-0.1138],\n",
      "        [ 0.0495],\n",
      "        [ 0.6097],\n",
      "        [-0.2552]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([[ 80],\n",
      "        [ 66],\n",
      "        [153],\n",
      "        [ 55],\n",
      "        [181]], device='cuda:0')\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "multi-target not supported at c:\\a\\w\\1\\s\\windows\\pytorch\\aten\\src\\thcunn\\generic/ClassNLLCriterion.cu:15",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-2c7471a934df>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmods\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvgg_based\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer_ft\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-16-be4c94d26966>\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m(model, criterion, optimizer, num_epochs)\u001b[0m\n\u001b[0;32m     22\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m                 \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m             \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    488\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 489\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    490\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m    902\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    903\u001b[0m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[1;32m--> 904\u001b[1;33m                                ignore_index=self.ignore_index, reduction=self.reduction)\n\u001b[0m\u001b[0;32m    905\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    906\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[0;32m   1968\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1969\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1970\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mnll_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1971\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1972\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mnll_loss\u001b[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[0;32m   1788\u001b[0m                          .format(input.size(0), target.size(0)))\n\u001b[0;32m   1789\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1790\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1791\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mdim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1792\u001b[0m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnll_loss2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: multi-target not supported at c:\\a\\w\\1\\s\\windows\\pytorch\\aten\\src\\thcunn\\generic/ClassNLLCriterion.cu:15"
     ]
    }
   ],
   "source": [
    "mods = train_model(vgg_based, criterion, optimizer_ft, num_epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "data_dir = \"alien_pred\"\n",
    "input_shape = 224\n",
    "mean = [0.5, 0.5, 0.5]\n",
    "std = [0.5, 0.5, 0.5]\n",
    "\n",
    "#data transformation\n",
    "data_transforms = {\n",
    "   'train': transforms.Compose([\n",
    "       transforms.CenterCrop(input_shape),\n",
    "       transforms.ToTensor(),\n",
    "       transforms.Normalize(mean, std)\n",
    "   ]),\n",
    "   'validation': transforms.Compose([\n",
    "       transforms.CenterCrop(input_shape),\n",
    "       transforms.ToTensor(),\n",
    "       transforms.Normalize(mean, std)\n",
    "   ]),\n",
    "}\n",
    "\n",
    "image_datasets = {\n",
    "   x: datasets.ImageFolder(\n",
    "       os.path.join(data_dir, x),\n",
    "       transform=data_transforms[x]\n",
    "   )\n",
    "   for x in ['train', 'validation']\n",
    "}\n",
    "\n",
    "dataloaders = {\n",
    "   x: torch.utils.data.DataLoader(\n",
    "       image_datasets[x], batch_size=32,\n",
    "       shuffle=True, num_workers=4\n",
    "   )\n",
    "   for x in ['train', 'validation']\n",
    "}\n",
    "\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'validation']}\n",
    "\n",
    "print(dataset_sizes)\n",
    "class_names = image_datasets['train'].classes\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer_ft = optim.SGD(vgg_based.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "\n",
    "def train_model(model, criterion, optimizer, num_epochs=25):\n",
    "   since = time.time()\n",
    "\n",
    "   for epoch in range(num_epochs):\n",
    "       print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "       print('-' * 10)\n",
    "\n",
    "       #set model to trainable\n",
    "       # model.train()\n",
    "\n",
    "       train_loss = 0\n",
    "\n",
    "       # Iterate over data.\n",
    "       for i, data in enumerate(dataloaders['train']):\n",
    "           inputs , labels = data\n",
    "           inputs = inputs.to(device)\n",
    "           labels = labels.to(device)\n",
    "\n",
    "           optimizer.zero_grad()\n",
    "          \n",
    "           with torch.set_grad_enabled(True):\n",
    "               outputs  = model(inputs)\n",
    "               loss = criterion(outputs, labels)\n",
    "\n",
    "           loss.backward()\n",
    "           optimizer.step()\n",
    "\n",
    "           train_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "           print('{} Loss: {:.4f}'.format(\n",
    "               'train', train_loss / dataset_sizes['train']))\n",
    "          \n",
    "   time_elapsed = time.time() - since\n",
    "   print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "       time_elapsed // 60, time_elapsed % 60))\n",
    "\n",
    "   return model\n",
    "\n",
    "def visualize_model(model, num_images=6):\n",
    "   was_training = model.training\n",
    "   model.eval()\n",
    "   images_so_far = 0\n",
    "   fig = plt.figure()\n",
    "\n",
    "   with torch.no_grad():\n",
    "       for i, (inputs, labels) in enumerate(dataloaders['validation']):\n",
    "           inputs = inputs.to(device)\n",
    "           labels = labels.to(device)\n",
    "\n",
    "           outputs = model(inputs)\n",
    "           _, preds = torch.max(outputs, 1)\n",
    "\n",
    "           for j in range(inputs.size()[0]):\n",
    "               images_so_far += 1\n",
    "               ax = plt.subplot(num_images//2, 2, images_so_far)\n",
    "               ax.axis('off')\n",
    "               ax.set_title('predicted: {} truth: {}'.format(class_names[preds[j]], class_names[labels[j]]))\n",
    "               img = inputs.cpu().data[j].numpy().transpose((1, 2, 0))\n",
    "               img = std * img + mean\n",
    "               ax.imshow(img)\n",
    "\n",
    "               if images_so_far == num_images:\n",
    "                   model.train(mode=was_training)\n",
    "                   return\n",
    "       model.train(mode=was_training)\n",
    "    \n",
    "vgg_based = train_model(vgg_based, criterion, optimizer_ft, num_epochs=25)\n",
    "\n",
    "visualize_model(vgg_based)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train = len(files)\n",
    "indices = list(range(num_train))\n",
    "split = int(np.floor(0.2 * num_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "np.random.seed(random_seed)\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "train_idx, valid_idx = indices[split:], indices[:split]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "valid_sampler = SubsetRandomSampler(valid_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sampler["
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "car_dataset[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "    # define transforms\n",
    "    valid_transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            normalize,\n",
    "    ])\n",
    "    if augment:\n",
    "        train_transform = transforms.Compose([\n",
    "            transforms.RandomCrop(32, padding=4),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            normalize,\n",
    "        ])\n",
    "    else:\n",
    "        train_transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            normalize,\n",
    "        ])\n",
    "\n",
    "    # load the dataset\n",
    "    train_dataset = datasets.CIFAR10(\n",
    "        root=data_dir, train=True,\n",
    "        download=True, transform=train_transform,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    normalize = transforms.Normalize(\n",
    "        mean=[0.4914, 0.4822, 0.4465],\n",
    "        std=[0.2023, 0.1994, 0.2010],\n",
    "    )\n",
    "\n",
    "    # define transforms\n",
    "    valid_transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            normalize,\n",
    "    ])\n",
    "    if augment:\n",
    "        train_transform = transforms.Compose([\n",
    "            transforms.RandomCrop(32, padding=4),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            normalize,\n",
    "        ])\n",
    "    else:\n",
    "        train_transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            normalize,\n",
    "        ])\n",
    "\n",
    "    # load the dataset\n",
    "    train_dataset = datasets.CIFAR10(\n",
    "        root=data_dir, train=True,\n",
    "        download=True, transform=train_transform,\n",
    "    )\n",
    "\n",
    "    valid_dataset = datasets.CIFAR10(\n",
    "        root=data_dir, train=True,\n",
    "        download=True, transform=valid_transform,\n",
    "    )\n",
    "\n",
    "    num_train = len(train_dataset)\n",
    "    indices = list(range(num_train))\n",
    "    split = int(np.floor(valid_size * num_train))\n",
    "\n",
    "    if shuffle:\n",
    "        np.random.seed(random_seed)\n",
    "        np.random.shuffle(indices)\n",
    "\n",
    "    train_idx, valid_idx = indices[split:], indices[:split]\n",
    "    train_sampler = SubsetRandomSampler(train_idx)\n",
    "    valid_sampler = SubsetRandomSampler(valid_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset = []\n",
    "columns = [\"x1\", \"y1\", \"x2\", \"y2\", \"class ID\", \"Model\",\"Image name\"]\n",
    "for example in annotations[\"annotations\"][0]:\n",
    "    \n",
    "    filename = example[-1][0]\n",
    "    annos = np.concatenate(list(example)[:-1]).ravel().tolist()\n",
    "    carmodel = meta[example[-2][0] - 1][0]\n",
    "    dataset.append(annos + [carmodel] + [filename])\n",
    "    \n",
    "dataset = pd.DataFrame(dataset, columns=columns)\n",
    "\n",
    "X = []\n",
    "y = dataset[\"type ID\"].values\n",
    "\n",
    "for idx, val in enumerate(dataset[[\"type ID\", \"Image name\"]].values):\n",
    "    img = mpimg.imread(os.path.join(carstrain_folder, val[1]))\n",
    "    flatten_img = list(cv2.resize(img[dataset.iloc[idx][\"y1\"]: dataset.iloc[idx][\"y2\"], dataset.iloc[idx][\"x1\"] : dataset.iloc[idx][\"x2\"]], (224,224)).flatten()/255)\n",
    "    X.append(flatten_img)\n",
    "    if idx % 1000 == 0:\n",
    "        print(\"{} images done\".format(idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToTensor(object):\n",
    "    \n",
    "    def transform_annotations(annotations):\n",
    "        \n",
    "    #bbox params\n",
    "        Image\n",
    "        \n",
    "    \n",
    "    def __call__(self, sample):\n",
    "        \n",
    "        tensor = torch.from_numpy(np.array(sample[\"image\"]/255).astype(np.float32))\n",
    "        target = torch.from_numpy(np.array(sample[\"target\"]).astype(np.float32))\n",
    "        \n",
    "        return {\"target\":target, \"image\":tensor}\n",
    "\n",
    "class mnist_dataset(Dataset):\n",
    "    \n",
    "    def __init__(self, csv_file, transform = None):\n",
    "        \n",
    "        df = pd.read_csv(csv_file)\n",
    "        self.target = pd.get_dummies(test[\"label\"]).values\n",
    "        self.variable = df.drop(columns=[\"label\"]).values\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.target)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        sample = {'target':self.target[idx],'image':self.variable[idx]}\n",
    "        \n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "            \n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#utils file\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "label_names = [\n",
    "    'airplane',\n",
    "    'automobile',\n",
    "    'bird',\n",
    "    'cat',\n",
    "    'deer',\n",
    "    'dog',\n",
    "    'frog',\n",
    "    'horse',\n",
    "    'ship',\n",
    "    'truck'\n",
    "]\n",
    "\n",
    "\n",
    "def plot_images(images, cls_true, cls_pred=None):\n",
    "    \"\"\"\n",
    "    Adapted from https://github.com/Hvass-Labs/TensorFlow-Tutorials/\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(3, 3)\n",
    "\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        # plot img\n",
    "        ax.imshow(images[i, :, :, :], interpolation='spline16')\n",
    "\n",
    "        # show true & predicted classes\n",
    "        cls_true_name = label_names[cls_true[i]]\n",
    "        if cls_pred is None:\n",
    "            xlabel = \"{0} ({1})\".format(cls_true_name, cls_true[i])\n",
    "        else:\n",
    "            cls_pred_name = label_names[cls_pred[i]]\n",
    "            xlabel = \"True: {0}\\nPred: {1}\".format(\n",
    "                cls_true_name, cls_pred_name\n",
    "            )\n",
    "        ax.set_xlabel(xlabel)\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
