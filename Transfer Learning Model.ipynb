{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import random\n",
    "from scipy.io import loadmat\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.utils.data.sampler import WeightedRandomSampler\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import time\n",
    "import utils\n",
    "import torch\n",
    "import torch.utils.data\n",
    "import torchvision\n",
    "\n",
    "seed = 10\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import Load_Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "root_dir = \"data/cars_train/\"\n",
    "car_annotations_path = \"data/devkit/cars_train_annos.mat\"\n",
    "car_metadata_path = \"data/devkit/cars_meta.mat\"\n",
    "\n",
    "#Load Meta Data\n",
    "meta_data = loadmat(car_metadata_path)\n",
    "meta_data = np.concatenate(meta_data[\"class_names\"][0])\n",
    "\n",
    "nb_classes = len(meta_data)\n",
    "\n",
    "dataset = Load_Images(root_dir = root_dir, annotations_path=car_annotations_path, seed=seed, train_split=0.8)\n",
    "\n",
    "\n",
    "#vgg16_tl.py --data-folder=\"data/cars_train/\" --meta-file=\"data/devkit/cars_meta.mat\" --annotation-file=\"data/devkit/cars_train_annos.mat\" --nb_epochs=2 --batch_size=15 --nb_classes=196 --enable_cuda "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  --annotation-file ANNOTATION\n",
    "                        annotation file path\n",
    "  --meta-fild META      meta data file path\n",
    "  --training-split [TRAINING_SPLIT]\n",
    "                        training and validation split. Default at .8\n",
    "  --nb_epochs [EPOCHS]  Number of epochs to train the model\n",
    "  --batch_size [BATCH_SIZE]\n",
    "                        batch size\n",
    "  --nb_classes NB_CLASSES\n",
    "                        Number of classes\n",
    "  --enable_cuda         Start using CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class car_dataset(Dataset):\n",
    "    \n",
    "    def __init__(self, files, root_dir, meta_data, image_transform=None):\n",
    "        \n",
    "        self.root_dir = root_dir\n",
    "        self.image_transform = image_transform\n",
    "        \n",
    "        #image file names\n",
    "        self.image_files = [file[-1][0] for file in files]\n",
    "        \n",
    "        #Class ID\n",
    "        #id needs to be adjusted by 1, for pytorch NLLosss \n",
    "        self.id = [file[-2][0] - 1 for file in files]\n",
    "        \n",
    "        #Class Name\n",
    "        self.class_name = [meta_data[file[-2][0] - 1][0] for file in files]\n",
    "        \n",
    "        #Get Car Year\n",
    "        self.carYear, self.carYear_ID = utils.get_Year(self.class_name)\n",
    "        \n",
    "        #Get Car Maker\n",
    "        self.carMaker, self.carMaker_ID = utils.get_Maker(self.class_name)\n",
    "        \n",
    "        #Get Car Type\n",
    "        self.carType, self.carType_ID = utils.get_Type(self.class_name)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.id)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.root_dir, self.image_files[idx])\n",
    "        img = Image.open(img_path)\n",
    "        \n",
    "        if self.image_transform:\n",
    "            img = self.image_transform(img)\n",
    "        \n",
    "        target = torch.from_numpy(np.array(self.id[idx]))[0]\n",
    "\n",
    "        sample = {'Image':img, 'class_ID':target, \"class_name\":self.class_name[idx],\n",
    "                 'year_ID':self.carYear_ID[idx], 'maker_ID':self.carMaker_ID[idx],\n",
    "                 'type_ID':self.carType_ID[idx]}\n",
    "        \n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImbalancedDatasetSampler(torch.utils.data.sampler.Sampler):\n",
    "    \"\"\"Samples elements randomly from a given list of indices for imbalanced dataset\n",
    "    Arguments:\n",
    "        indices (list, optional): a list of indices\n",
    "        num_samples (int, optional): number of samples to draw\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dataset, class_type):\n",
    "                      \n",
    "        self.indices = list(range(len(dataset)))\n",
    "        \n",
    "        self.num_samples = len(self.indices) \n",
    "        # distribution of classes in the dataset \n",
    "        label_to_count = {}\n",
    "        for idx in self.indices:\n",
    "            label = self._get_label(dataset, idx, class_type)\n",
    "            if label in label_to_count:\n",
    "                label_to_count[label] += 1\n",
    "            else:\n",
    "                label_to_count[label] = 1\n",
    "        # weight for each sample\n",
    "        weights = [1.0 / label_to_count[self._get_label(dataset, idx, class_type)] for idx in self.indices]\n",
    "        self.weights = torch.DoubleTensor(weights)\n",
    "\n",
    "    def _get_label(self, dataset, idx, class_type):\n",
    "        return dataset[idx][class_type].item()\n",
    "                \n",
    "    def __iter__(self):\n",
    "        return (self.indices[i] for i in torch.multinomial(\n",
    "                self.weights, self.num_samples, replacement=True))\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Training Weighted Random Sampler\n",
    "\n",
    "\"\"\"targets = [i[-2][0][0] for i in dataset[\"training\"]]\n",
    "class_sample_counts=[len(np.where(targets == t)[0]) for t in np.unique(targets)]\n",
    "weight = 1. / np.array(class_sample_counts)\n",
    "samples_weight = np.array([weight[t-1] for t in targets])\n",
    "samples_weight = torch.from_numpy(samples_weight)\n",
    "samples_weight = samples_weight.double()\n",
    "training_sampler = WeightedRandomSampler(samples_weight, num_samples=len(samples_weight), replacement=False)\n",
    "\"\"\"\n",
    "#batch size\n",
    "bs = 15\n",
    "\n",
    "image_transformers = {'train': transforms.Compose([transforms.Resize((244,244)),\n",
    "                                                   transforms.RandomRotation(degrees=50),\n",
    "                                                   transforms.RandomHorizontalFlip(0.8),\n",
    "                                                   transforms.RandomPerspective(),\n",
    "                                                   transforms.RandomResizedCrop(size=((244,244)), scale = (0.8, 1.0)),\n",
    "                                                   transforms.ColorJitter(brightness=0.8, contrast=0.8),\n",
    "                                                   transforms.ToTensor()]),\n",
    "                      'validation': transforms.Compose([transforms.Resize((244,244)),\n",
    "                                                       transforms.ToTensor()\n",
    "                                                       ])\n",
    "                     }\n",
    "\n",
    "#\n",
    "training_data = car_dataset(dataset[\"training\"],\n",
    "                            root_dir = root_dir,\n",
    "                            meta_data = meta_data,\n",
    "                            image_transform = image_transformers[\"train\"]\n",
    "                           )\n",
    "train_loader = torch.utils.data.DataLoader(training_data, batch_size=bs, \n",
    "                                           sampler=ImbalancedDatasetSampler(training_data, \"year_ID\"))\n",
    "\n",
    "validation_data = car_dataset(dataset[\"validation\"], \n",
    "                             root_dir = root_dir,\n",
    "                             meta_data = meta_data,\n",
    "                             image_transform  = image_transformers[\"validation\"])\n",
    "validation_loader = torch.utils.data.DataLoader(validation_data, batch_size=bs,\n",
    "                                                shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_ids = [i[\"year_ID\"] for i in training_data]\n",
    "#validation_ids = [i[\"class_name\"] for i in validation_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(pd.Series(training_ids).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_classes = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache() \n",
    "print(\"GPU: {}\".format(torch.cuda.get_device_name(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")\n",
    "#device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Load the model based on VGG19\n",
    "vgg_based = torchvision.models.vgg19(pretrained=True)\n",
    "\n",
    "'''\n",
    "for param in vgg_based.parameters():\n",
    "    param.requires_grad = False\n",
    "'''\n",
    "\n",
    "\n",
    "for idx,param in enumerate(vgg_based.parameters()):\n",
    "    if idx <= 35:\n",
    "        param.requires_grad = False\n",
    "    \n",
    "# Modify the last layer\n",
    "number_features = vgg_based.classifier[6].in_features\n",
    "features = list(vgg_based.classifier.children())[:-1] # Remove last layer\n",
    "features.extend([torch.nn.Linear(number_features, nb_classes)])\n",
    "vgg_based.classifier = torch.nn.Sequential(*features)\n",
    "\n",
    "vgg_based = vgg_based.to(device)\n",
    "\n",
    "print(vgg_based)\n",
    "#torch.optim.Adagrad(params, lr=0.01, lr_decay=0, weight_decay=0, initial_accumulator_value=0)\n",
    "#\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer_ft = torch.optim.Adam(vgg_based.parameters(), lr= 0.0001, weight_decay=1e-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimizer_ft = torch.optim.Adam(vgg_based.parameters(), lr= 0.001, weight_decay=1e-5)\n",
    "#torch.optim.Adam(vgg_based.parameters(), lr= 0.0001, weight_decay=1e-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, num_epochs=1):\n",
    "    since = time.time()\n",
    "    history = []\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch + 1, num_epochs))\n",
    "        print('-' * 30)\n",
    "\n",
    "        training_loss = 0\n",
    "        validation_loss = 0\n",
    "        \n",
    "        training_accuracy = 0\n",
    "        validation_accuracy = 0\n",
    "\n",
    "        # Iterate over data.\n",
    "        for batch_idx, data in enumerate(train_loader):\n",
    "            inputs = data[\"Image\"]\n",
    "            labels = data[\"year_ID\"]\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            labels = labels.long()\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            with torch.set_grad_enabled(True):\n",
    "                outputs  = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Compute the total loss for the batch and add it to valid_loss\n",
    "            training_loss += loss.item() * inputs.size(0)\n",
    "            \n",
    "            #train accuracy\n",
    "            (max_vals, arg_maxs) = torch.max(outputs, dim=1) \n",
    "            correct_counts = arg_maxs.eq(labels.data.view_as(arg_maxs))\n",
    "\n",
    "            acc = torch.mean(correct_counts.type(torch.FloatTensor))\n",
    "\n",
    "            \n",
    "            # Compute total accuracy in the whole batch and add to valid_acc\n",
    "            training_accuracy += acc.item() * inputs.size(0)\n",
    "\n",
    "            \n",
    "        #get accuracy\n",
    "        with torch.no_grad():\n",
    "            \n",
    "            model.eval()\n",
    "            \n",
    "            for batch_idx, data in enumerate(validation_loader):\n",
    "                inputs = data[\"Image\"]\n",
    "                labels = data[\"year_ID\"]\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                labels = labels.long()\n",
    "\n",
    "                outputs = model(inputs)\n",
    "\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                validation_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "                #train accuracy\n",
    "                (max_vals, arg_maxs) = torch.max(outputs, dim=1) \n",
    "                correct_counts = arg_maxs.eq(labels.data.view_as(arg_maxs))\n",
    "\n",
    "                # Convert correct_counts to float and then compute the mean\n",
    "                acc = torch.mean(correct_counts.type(torch.FloatTensor))\n",
    "\n",
    "                # Compute total accuracy in the whole batch and add to valid_acc\n",
    "                validation_accuracy += acc.item() * inputs.size(0)\n",
    "\n",
    "        # Find average training loss and training accuracy\n",
    "        avg_train_loss = training_loss/len(training_data)\n",
    "        avg_train_acc = training_accuracy/float(len(training_data))\n",
    "\n",
    "        # Find average training loss and training accuracy\n",
    "        avg_valid_loss = validation_loss/len(validation_data)\n",
    "        avg_valid_acc = validation_accuracy/float(len(validation_data))\n",
    "        history.append([avg_train_loss, avg_train_acc, avg_valid_loss, avg_valid_acc])\n",
    "        print(\"Epoch : {:03d}, Training: Loss: {:.4f}, Accuracy: {:.4f}%, \\n\\t\\tValidation : Loss : {:.4f}, Accuracy: {:.4f}%\".format(epoch + 1, avg_train_loss, avg_train_acc*100, avg_valid_loss, avg_valid_acc*100))\n",
    "        \n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "\n",
    "\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mods, history = train_model(vgg_based, criterion, optimizer_ft, num_epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    yhats = []  \n",
    "    ys = []\n",
    "    mods.eval()\n",
    "\n",
    "    for batch_idx, data in enumerate(validation_loader):\n",
    "        inputs = data[\"Image\"]\n",
    "        labels = data[\"class_ID\"]\n",
    "        ys.append(labels)\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        labels = labels.long()\n",
    "        yhats.append(mods(inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "for i in yhats:\n",
    "    for g in i:\n",
    "        _, ind = torch.max(g, 0)\n",
    "        preds.append(ind.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "values, indices = torch.max(yhats[0], 0)\n",
    "print(values, indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = []\n",
    "for i in ys:\n",
    "    for g in i.numpy():\n",
    "        targets.append(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets\n",
    "im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(history, columns=[\"avg_train_loss\", \"avg_train_acc\", \"avg_valid_loss\", \"avg_valid_acc\"])[[\"avg_valid_acc\", \"avg_train_acc\"]].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, test_image_name):\n",
    "     \n",
    "    transform = image_transforms['test']\n",
    " \n",
    "    test_image = Image.open(test_image_name)\n",
    "    plt.imshow(test_image)\n",
    "     \n",
    "    test_image_tensor = transform(test_image)\n",
    " \n",
    "    if torch.cuda.is_available():\n",
    "        test_image_tensor = test_image_tensor.view(1, 3, 224, 224).cuda()\n",
    "    else:\n",
    "        test_image_tensor = test_image_tensor.view(1, 3, 224, 224)\n",
    "     \n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        # Model outputs log probabilities\n",
    "        out = model(test_image_tensor)\n",
    "        ps = torch.exp(out)\n",
    "        topk, topclass = ps.topk(1, dim=1)\n",
    "        print(\"Output class :  \", idx_to_class[topclass.cpu().numpy()[0][0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "class CustomDatasetFromCSV(Dataset):\n",
    "    def __init__(self, csv_path, transform=None):\n",
    "        self.data = pd.read_csv(csv_path)\n",
    "        self.labels = pd.get_dummies(self.data['emotion']).as_matrix()\n",
    "        self.height = 48\n",
    "        self.width = 48\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # This method should return only 1 sample and label \n",
    "        # (according to \"index\"), not the whole dataset\n",
    "        # So probably something like this for you:\n",
    "        pixel_sequence = self.data['pixels'][index]\n",
    "        face = [int(pixel) for pixel in pixel_sequence.split(' ')]\n",
    "        face = np.asarray(face).reshape(self.width, self.height)\n",
    "        face = cv2.resize(face.astype('uint8'), (self.width, self.height))\n",
    "        label = self.labels[index]\n",
    "\n",
    "        return face, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "\n",
    "dataset = CustomDatasetFromCSV(my_path)\n",
    "batch_size = 16\n",
    "validation_split = .2\n",
    "shuffle_dataset = True\n",
    "random_seed= 42\n",
    "\n",
    "# Creating data indices for training and validation splits:\n",
    "dataset_size = len(dataset)\n",
    "indices = list(range(dataset_size))\n",
    "split = int(np.floor(validation_split * dataset_size))\n",
    "if shuffle_dataset :\n",
    "    np.random.seed(random_seed)\n",
    "    np.random.shuffle(indices)\n",
    "train_indices, val_indices = indices[split:], indices[:split]\n",
    "\n",
    "# Creating PT data samplers and loaders:\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "valid_sampler = SubsetRandomSampler(val_indices)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, \n",
    "                                           sampler=train_sampler)\n",
    "validation_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size,\n",
    "                                                sampler=valid_sampler)\n",
    "\n",
    "# Usage Example:\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    # Train:   \n",
    "    for batch_index, (faces, labels) in enumerate(train_loader):\n",
    "        # ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImbalancedDatasetSampler(torch.utils.data.sampler.Sampler):\n",
    "    \"\"\"Samples elements randomly from a given list of indices for imbalanced dataset\n",
    "    Arguments:\n",
    "        indices (list, optional): a list of indices\n",
    "        num_samples (int, optional): number of samples to draw\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dataset, indices=None, num_samples=None):\n",
    "                \n",
    "        # if indices is not provided, \n",
    "        # all elements in the dataset will be considered\n",
    "        self.indices = list(range(len(dataset))) \\\n",
    "            if indices is None else indices\n",
    "            \n",
    "        # if num_samples is not provided, \n",
    "        # draw `len(indices)` samples in each iteration\n",
    "        self.num_samples = len(self.indices) \\\n",
    "            if num_samples is None else num_samples\n",
    "            \n",
    "        # distribution of classes in the dataset \n",
    "        label_to_count = {}\n",
    "        for idx in self.indices:\n",
    "            label = self._get_label(dataset, idx)\n",
    "            if label in label_to_count:\n",
    "                label_to_count[label] += 1\n",
    "            else:\n",
    "                label_to_count[label] = 1\n",
    "                \n",
    "        # weight for each sample\n",
    "        weights = [1.0 / label_to_count[self._get_label(dataset, idx)]\n",
    "                   for idx in self.indices]\n",
    "        self.weights = torch.DoubleTensor(weights)\n",
    "\n",
    "    def _get_label(self, dataset, idx):\n",
    "        dataset_type = type(dataset)\n",
    "        if dataset_type is torchvision.datasets.MNIST:\n",
    "            return dataset.train_labels[idx].item()\n",
    "        elif dataset_type is torchvision.datasets.ImageFolder:\n",
    "            return dataset.imgs[idx][1]\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "                \n",
    "    def __iter__(self):\n",
    "        return (self.indices[i] for i in torch.multinomial(\n",
    "            self.weights, self.num_samples, replacement=True))\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "data_dir = \"alien_pred\"\n",
    "input_shape = 224\n",
    "mean = [0.5, 0.5, 0.5]\n",
    "std = [0.5, 0.5, 0.5]\n",
    "\n",
    "#data transformation\n",
    "data_transforms = {\n",
    "   'train': transforms.Compose([\n",
    "       transforms.CenterCrop(input_shape),\n",
    "       transforms.ToTensor(),\n",
    "       transforms.Normalize(mean, std)\n",
    "   ]),\n",
    "   'validation': transforms.Compose([\n",
    "       transforms.CenterCrop(input_shape),\n",
    "       transforms.ToTensor(),\n",
    "       transforms.Normalize(mean, std)\n",
    "   ]),\n",
    "}\n",
    "\n",
    "image_datasets = {\n",
    "   x: datasets.ImageFolder(\n",
    "       os.path.join(data_dir, x),\n",
    "       transform=data_transforms[x]\n",
    "   )\n",
    "   for x in ['train', 'validation']\n",
    "}\n",
    "\n",
    "dataloaders = {\n",
    "   x: torch.utils.data.DataLoader(\n",
    "       image_datasets[x], batch_size=32,\n",
    "       shuffle=True, num_workers=4\n",
    "   )\n",
    "   for x in ['train', 'validation']\n",
    "}\n",
    "\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'validation']}\n",
    "\n",
    "print(dataset_sizes)\n",
    "class_names = image_datasets['train'].classes\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer_ft = optim.SGD(vgg_based.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "\n",
    "def train_model(model, criterion, optimizer, num_epochs=25):\n",
    "   since = time.time()\n",
    "\n",
    "   for epoch in range(num_epochs):\n",
    "       print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "       print('-' * 10)\n",
    "\n",
    "       #set model to trainable\n",
    "       # model.train()\n",
    "\n",
    "       train_loss = 0\n",
    "\n",
    "       # Iterate over data.\n",
    "       for i, data in enumerate(dataloaders['train']):\n",
    "           inputs , labels = data\n",
    "           inputs = inputs.to(device)\n",
    "           labels = labels.to(device)\n",
    "\n",
    "           optimizer.zero_grad()\n",
    "          \n",
    "           with torch.set_grad_enabled(True):\n",
    "               outputs  = model(inputs)\n",
    "               loss = criterion(outputs, labels)\n",
    "\n",
    "           loss.backward()\n",
    "           optimizer.step()\n",
    "\n",
    "           train_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "           print('{} Loss: {:.4f}'.format(\n",
    "               'train', train_loss / dataset_sizes['train']))\n",
    "          \n",
    "   time_elapsed = time.time() - since\n",
    "   print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "       time_elapsed // 60, time_elapsed % 60))\n",
    "\n",
    "   return model\n",
    "\n",
    "def visualize_model(model, num_images=6):\n",
    "   was_training = model.training\n",
    "   model.eval()\n",
    "   images_so_far = 0\n",
    "   fig = plt.figure()\n",
    "\n",
    "   with torch.no_grad():\n",
    "       for i, (inputs, labels) in enumerate(dataloaders['validation']):\n",
    "           inputs = inputs.to(device)\n",
    "           labels = labels.to(device)\n",
    "\n",
    "           outputs = model(inputs)\n",
    "           _, preds = torch.max(outputs, 1)\n",
    "\n",
    "           for j in range(inputs.size()[0]):\n",
    "               images_so_far += 1\n",
    "               ax = plt.subplot(num_images//2, 2, images_so_far)\n",
    "               ax.axis('off')\n",
    "               ax.set_title('predicted: {} truth: {}'.format(class_names[preds[j]], class_names[labels[j]]))\n",
    "               img = inputs.cpu().data[j].numpy().transpose((1, 2, 0))\n",
    "               img = std * img + mean\n",
    "               ax.imshow(img)\n",
    "\n",
    "               if images_so_far == num_images:\n",
    "                   model.train(mode=was_training)\n",
    "                   return\n",
    "       model.train(mode=was_training)\n",
    "    \n",
    "vgg_based = train_model(vgg_based, criterion, optimizer_ft, num_epochs=25)\n",
    "\n",
    "visualize_model(vgg_based)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
