{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import random\n",
    "from scipy.io import loadmat\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.utils.data.sampler import WeightedRandomSampler\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import time\n",
    "import utils\n",
    "import torch\n",
    "import torch.utils.data\n",
    "import torchvision\n",
    "import utils\n",
    "\n",
    "seed = 10\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = \"data/cars_train/\" # folder Images location\n",
    "car_annotations_path = \"data/devkit/cars_train_annos.mat\"\n",
    "car_metadata_path = \"data/devkit/cars_meta.mat\"\n",
    "\n",
    "#Load Meta Data\n",
    "meta_data = loadmat(car_metadata_path)\n",
    "meta_data = np.concatenate(meta_data[\"class_names\"][0])\n",
    "\n",
    "nb_classes = len(meta_data)\n",
    "\n",
    "dataset = Load_Images(root_dir = root_dir, annotations_path=car_annotations_path, seed=seed, train_split=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class car_dataset(Dataset):\n",
    "    \n",
    "    def __init__(self, files, root_dir, meta_data, image_transform=None):\n",
    "        \n",
    "        self.root_dir = root_dir\n",
    "        self.image_transform = image_transform\n",
    "        \n",
    "        #image file names\n",
    "        self.image_files = [file[-1][0] for file in files]\n",
    "        \n",
    "        #Class ID\n",
    "        #id needs to be adjusted by 1, for pytorch NLLosss \n",
    "        self.id = [file[-2][0] - 1 for file in files]\n",
    "        \n",
    "        #Class Name\n",
    "        self.class_name = [meta_data[file[-2][0] - 1][0] for file in files]\n",
    "        \n",
    "        #Get Car Year\n",
    "        self.carYear, self.carYear_ID = utils.get_Year(self.class_name)\n",
    "        \n",
    "        #Get Car Maker\n",
    "        self.carMaker, self.carMaker_ID = utils.get_Maker(self.class_name)\n",
    "        \n",
    "        #Get Car Type\n",
    "        self.carType, self.carType_ID = utils.get_Type(self.class_name)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.id)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.root_dir, self.image_files[idx])\n",
    "        img = Image.open(img_path)\n",
    "        \n",
    "        if self.image_transform:\n",
    "            img = self.image_transform(img)\n",
    "        \n",
    "        target = torch.from_numpy(np.array(self.id[idx]))[0]\n",
    "\n",
    "        sample = {'Image':img, 'class_ID':target, \"class_name\":self.class_name[idx],\n",
    "                 'year_ID':self.carYear_ID[idx], 'maker_ID':self.carMaker_ID[idx],\n",
    "                 'type_ID':self.carType_ID[idx]}\n",
    "        \n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImbalancedDatasetSampler(torch.utils.data.sampler.Sampler):\n",
    "    \"\"\"Samples elements randomly from a given list of indices for imbalanced dataset\n",
    "    Arguments:\n",
    "        indices (list, optional): a list of indices\n",
    "        num_samples (int, optional): number of samples to draw\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dataset, class_type):\n",
    "                      \n",
    "        self.indices = list(range(len(dataset)))\n",
    "        \n",
    "        self.num_samples = len(self.indices) \n",
    "        # distribution of classes in the dataset \n",
    "        label_to_count = {}\n",
    "        for idx in self.indices:\n",
    "            label = self._get_label(dataset, idx, class_type)\n",
    "            if label in label_to_count:\n",
    "                label_to_count[label] += 1\n",
    "            else:\n",
    "                label_to_count[label] = 1\n",
    "        # weight for each sample\n",
    "        weights = [1.0 / label_to_count[self._get_label(dataset, idx, class_type)] for idx in self.indices]\n",
    "        self.weights = torch.DoubleTensor(weights)\n",
    "\n",
    "    def _get_label(self, dataset, idx, class_type):\n",
    "        return dataset[idx][class_type].item()\n",
    "                \n",
    "    def __iter__(self):\n",
    "        return (self.indices[i] for i in torch.multinomial(\n",
    "                self.weights, self.num_samples, replacement=True))\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Training Weighted Random Sampler\n",
    "#batch size\n",
    "bs = 15\n",
    "\n",
    "image_transformers = {'train': transforms.Compose([transforms.Resize((244,244)),\n",
    "                                                   transforms.RandomRotation(degrees=50),\n",
    "                                                   transforms.RandomHorizontalFlip(0.8),\n",
    "                                                   transforms.RandomPerspective(),\n",
    "                                                   transforms.RandomResizedCrop(size=((244,244)), scale = (0.8, 1.0)),\n",
    "                                                   transforms.ColorJitter(brightness=0.8, contrast=0.8),\n",
    "                                                   transforms.ToTensor()]),\n",
    "                      'validation': transforms.Compose([transforms.Resize((244,244)),\n",
    "                                                       transforms.ToTensor()\n",
    "                                                       ])\n",
    "                     }\n",
    "\n",
    "#\n",
    "training_data = car_dataset(dataset[\"training\"],\n",
    "                            root_dir = root_dir,\n",
    "                            meta_data = meta_data,\n",
    "                            image_transform = image_transformers[\"train\"]\n",
    "                           )\n",
    "train_loader = torch.utils.data.DataLoader(training_data, batch_size=bs, \n",
    "                                           sampler=ImbalancedDatasetSampler(training_data, \"year_ID\"))\n",
    "\n",
    "validation_data = car_dataset(dataset[\"validation\"], \n",
    "                             root_dir = root_dir,\n",
    "                             meta_data = meta_data,\n",
    "                             image_transform  = image_transformers[\"validation\"])\n",
    "validation_loader = torch.utils.data.DataLoader(validation_data, batch_size=bs,\n",
    "                                                shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_ids = [i[\"year_ID\"] for i in training_data]\n",
    "#validation_ids = [i[\"class_name\"] for i in validation_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(pd.Series(training_ids).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_classes = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache() \n",
    "print(\"GPU: {}\".format(torch.cuda.get_device_name(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")\n",
    "#device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Load the model based on VGG19\n",
    "vgg_based = torchvision.models.vgg19(pretrained=True)\n",
    "\n",
    "for idx,param in enumerate(vgg_based.parameters()):\n",
    "    if idx <= 35:\n",
    "        param.requires_grad = False\n",
    "    \n",
    "# Modify the last layer\n",
    "number_features = vgg_based.classifier[6].in_features\n",
    "features = list(vgg_based.classifier.children())[:-1] # Remove last layer\n",
    "features.extend([torch.nn.Linear(number_features, nb_classes)])\n",
    "vgg_based.classifier = torch.nn.Sequential(*features)\n",
    "\n",
    "vgg_based = vgg_based.to(device)\n",
    "\n",
    "print(vgg_based)\n",
    "#torch.optim.Adagrad(params, lr=0.01, lr_decay=0, weight_decay=0, initial_accumulator_value=0)\n",
    "#\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer_ft = torch.optim.Adam(vgg_based.parameters(), lr= 0.0001, weight_decay=1e-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimizer_ft = torch.optim.Adam(vgg_based.parameters(), lr= 0.001, weight_decay=1e-5)\n",
    "#torch.optim.Adam(vgg_based.parameters(), lr= 0.0001, weight_decay=1e-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, num_epochs=1):\n",
    "    since = time.time()\n",
    "    history = []\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch + 1, num_epochs))\n",
    "        print('-' * 30)\n",
    "\n",
    "        training_loss = 0\n",
    "        validation_loss = 0\n",
    "        \n",
    "        training_accuracy = 0\n",
    "        validation_accuracy = 0\n",
    "\n",
    "        # Iterate over data.\n",
    "        for batch_idx, data in enumerate(train_loader):\n",
    "            inputs = data[\"Image\"]\n",
    "            labels = data[\"year_ID\"]\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            labels = labels.long()\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            with torch.set_grad_enabled(True):\n",
    "                outputs  = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Compute the total loss for the batch and add it to valid_loss\n",
    "            training_loss += loss.item() * inputs.size(0)\n",
    "            \n",
    "            #train accuracy\n",
    "            (max_vals, arg_maxs) = torch.max(outputs, dim=1) \n",
    "            correct_counts = arg_maxs.eq(labels.data.view_as(arg_maxs))\n",
    "\n",
    "            acc = torch.mean(correct_counts.type(torch.FloatTensor))\n",
    "\n",
    "            \n",
    "            # Compute total accuracy in the whole batch and add to valid_acc\n",
    "            training_accuracy += acc.item() * inputs.size(0)\n",
    "\n",
    "            \n",
    "        #get accuracy\n",
    "        with torch.no_grad():\n",
    "            \n",
    "            model.eval()\n",
    "            \n",
    "            for batch_idx, data in enumerate(validation_loader):\n",
    "                inputs = data[\"Image\"]\n",
    "                labels = data[\"year_ID\"]\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                labels = labels.long()\n",
    "\n",
    "                outputs = model(inputs)\n",
    "\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                validation_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "                #train accuracy\n",
    "                (max_vals, arg_maxs) = torch.max(outputs, dim=1) \n",
    "                correct_counts = arg_maxs.eq(labels.data.view_as(arg_maxs))\n",
    "\n",
    "                # Convert correct_counts to float and then compute the mean\n",
    "                acc = torch.mean(correct_counts.type(torch.FloatTensor))\n",
    "\n",
    "                # Compute total accuracy in the whole batch and add to valid_acc\n",
    "                validation_accuracy += acc.item() * inputs.size(0)\n",
    "\n",
    "        # Find average training loss and training accuracy\n",
    "        avg_train_loss = training_loss/len(training_data)\n",
    "        avg_train_acc = training_accuracy/float(len(training_data))\n",
    "\n",
    "        # Find average training loss and training accuracy\n",
    "        avg_valid_loss = validation_loss/len(validation_data)\n",
    "        avg_valid_acc = validation_accuracy/float(len(validation_data))\n",
    "        history.append([avg_train_loss, avg_train_acc, avg_valid_loss, avg_valid_acc])\n",
    "        print(\"Epoch : {:03d}, Training: Loss: {:.4f}, Accuracy: {:.4f}%, \\n\\t\\tValidation : Loss : {:.4f}, Accuracy: {:.4f}%\".format(epoch + 1, avg_train_loss, avg_train_acc*100, avg_valid_loss, avg_valid_acc*100))\n",
    "        \n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "\n",
    "\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mods, history = train_model(vgg_based, criterion, optimizer_ft, num_epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    yhats = []  \n",
    "    ys = []\n",
    "    mods.eval()\n",
    "\n",
    "    for batch_idx, data in enumerate(validation_loader):\n",
    "        inputs = data[\"Image\"]\n",
    "        labels = data[\"class_ID\"]\n",
    "        ys.append(labels)\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        labels = labels.long()\n",
    "        yhats.append(mods(inputs))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
